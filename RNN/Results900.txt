kostakis@DESKTOP-HM9Q2U8:~/dev/Akis-Kostakis-Diploma-Thesis/RNN$ ./lstm.out --epochs 900
LSTM Multi-Step Ahead Prediction
Configuration:
Lookback window (K): 10 timesteps
  Prediction horizon (N): 10 timesteps
  Input features: 9
  Output features: 3
  Epochs: 900

Data/dataset_1.csv rows: 3397 Cols: 9 (3397x9)
Number of training samples: 3378 after removing windowSize and loopback
Converted eigen matrix to Tensor
Tensor shape: [3397, 9]
Angles tensor shape: [3397, 3]

Data Shapes
X (inputs):  [3378, 10, 9]
y (targets): [3378, 10, 3]

Model Created
Architecture: Input(9) -> LSTM(128) -> FC(30)

Training Configuration
Batch size: 32
Epochs: 900
Learning rate: 0.001
Optimizer: Adam
Loss function: torch::nn::MSELossImpl

Starting Training
Epoch   0 | Loss: 0.005265
Epoch   5 | Loss: 0.000530
Epoch  10 | Loss: 0.000481
Epoch  15 | Loss: 0.000468
Epoch  20 | Loss: 0.000445
Epoch  25 | Loss: 0.000425
Epoch  30 | Loss: 0.000415
Epoch  35 | Loss: 0.000406
Epoch  40 | Loss: 0.000390
Epoch  45 | Loss: 0.000394
Epoch  50 | Loss: 0.000377
Epoch  55 | Loss: 0.000369
Epoch  60 | Loss: 0.000350
Epoch  65 | Loss: 0.000350
Epoch  70 | Loss: 0.000350
Epoch  75 | Loss: 0.000332
Epoch  80 | Loss: 0.000339
Epoch  85 | Loss: 0.000340
Epoch  90 | Loss: 0.000331
Epoch  95 | Loss: 0.000321
  -- Saved model: lstm_model_epoch_100.pt
Epoch 100 | Loss: 0.000317
Epoch 105 | Loss: 0.000327
Epoch 110 | Loss: 0.000314
Epoch 115 | Loss: 0.000313
Epoch 120 | Loss: 0.000315
Epoch 125 | Loss: 0.000307
Epoch 130 | Loss: 0.000310
Epoch 135 | Loss: 0.000306
Epoch 140 | Loss: 0.000296
Epoch 145 | Loss: 0.000304
Epoch 150 | Loss: 0.000293
Epoch 155 | Loss: 0.000303
Epoch 160 | Loss: 0.000301
Epoch 165 | Loss: 0.000291
Epoch 170 | Loss: 0.000300
Epoch 175 | Loss: 0.000294
Epoch 180 | Loss: 0.000292
Epoch 185 | Loss: 0.000288
Epoch 190 | Loss: 0.000287
Epoch 195 | Loss: 0.000293
  -- Saved model: lstm_model_epoch_200.pt
Epoch 200 | Loss: 0.000291
Epoch 205 | Loss: 0.000288
Epoch 210 | Loss: 0.000295
Epoch 215 | Loss: 0.000287
Epoch 220 | Loss: 0.000292
Epoch 225 | Loss: 0.000283
Epoch 230 | Loss: 0.000283
Epoch 235 | Loss: 0.000279
Epoch 240 | Loss: 0.000279
Epoch 245 | Loss: 0.000281
Epoch 250 | Loss: 0.000283
Epoch 255 | Loss: 0.000280
Epoch 260 | Loss: 0.000284
Epoch 265 | Loss: 0.000279
Epoch 270 | Loss: 0.000281
Epoch 275 | Loss: 0.000278
Epoch 280 | Loss: 0.000285
Epoch 285 | Loss: 0.000283
Epoch 290 | Loss: 0.000279
Epoch 295 | Loss: 0.000270
  -- Saved model: lstm_model_epoch_300.pt
Epoch 300 | Loss: 0.000280
Epoch 305 | Loss: 0.000278
Epoch 310 | Loss: 0.000276
Epoch 315 | Loss: 0.000272
Epoch 320 | Loss: 0.000273
Epoch 325 | Loss: 0.000280
Epoch 330 | Loss: 0.000276
Epoch 335 | Loss: 0.000278
Epoch 340 | Loss: 0.000272
Epoch 345 | Loss: 0.000271
Epoch 350 | Loss: 0.000279
Epoch 355 | Loss: 0.000279
Epoch 360 | Loss: 0.000269
Epoch 365 | Loss: 0.000275
Epoch 370 | Loss: 0.000289
Epoch 375 | Loss: 0.000270
Epoch 380 | Loss: 0.000283
Epoch 385 | Loss: 0.000265
Epoch 390 | Loss: 0.000276
Epoch 395 | Loss: 0.000275
  -- Saved model: lstm_model_epoch_400.pt
Epoch 400 | Loss: 0.000271
Epoch 405 | Loss: 0.000278
Epoch 410 | Loss: 0.000274
Epoch 415 | Loss: 0.000267
Epoch 420 | Loss: 0.000274
Epoch 425 | Loss: 0.000268
Epoch 430 | Loss: 0.000280
Epoch 435 | Loss: 0.000270
Epoch 440 | Loss: 0.000268
Epoch 445 | Loss: 0.000275
Epoch 450 | Loss: 0.000272
Epoch 455 | Loss: 0.000266
Epoch 460 | Loss: 0.000266
Epoch 465 | Loss: 0.000274
Epoch 470 | Loss: 0.000273
Epoch 475 | Loss: 0.000263
Epoch 480 | Loss: 0.000268
Epoch 485 | Loss: 0.000266
Epoch 490 | Loss: 0.000277
Epoch 495 | Loss: 0.000270
  -- Saved model: lstm_model_epoch_500.pt
Epoch 500 | Loss: 0.000273
Epoch 505 | Loss: 0.000274
Epoch 510 | Loss: 0.000272
Epoch 515 | Loss: 0.000269
Epoch 520 | Loss: 0.000270
Epoch 525 | Loss: 0.000272
Epoch 530 | Loss: 0.000264
Epoch 535 | Loss: 0.000273
Epoch 540 | Loss: 0.000272
Epoch 545 | Loss: 0.000273
Epoch 550 | Loss: 0.000279
Epoch 555 | Loss: 0.000270
Epoch 560 | Loss: 0.000270
Epoch 565 | Loss: 0.000266
Epoch 570 | Loss: 0.000264
Epoch 575 | Loss: 0.000270
Epoch 580 | Loss: 0.000268
Epoch 585 | Loss: 0.000264
Epoch 590 | Loss: 0.000268
Epoch 595 | Loss: 0.000273
  -- Saved model: lstm_model_epoch_600.pt
Epoch 600 | Loss: 0.000265
Epoch 605 | Loss: 0.000276
Epoch 610 | Loss: 0.000271
Epoch 615 | Loss: 0.000268
Epoch 620 | Loss: 0.000272
Epoch 625 | Loss: 0.000274
Epoch 630 | Loss: 0.000273
Epoch 635 | Loss: 0.000277
Epoch 640 | Loss: 0.000266
Epoch 645 | Loss: 0.000264
Epoch 650 | Loss: 0.000268
Epoch 655 | Loss: 0.000270
Epoch 660 | Loss: 0.000267
Epoch 665 | Loss: 0.000265
Epoch 670 | Loss: 0.000274
Epoch 675 | Loss: 0.000274
Epoch 680 | Loss: 0.000272
Epoch 685 | Loss: 0.000270
Epoch 690 | Loss: 0.000266
Epoch 695 | Loss: 0.000270
  -- Saved model: lstm_model_epoch_700.pt
Epoch 700 | Loss: 0.000270
Epoch 705 | Loss: 0.000267
Epoch 710 | Loss: 0.000268
Epoch 715 | Loss: 0.000264
Epoch 720 | Loss: 0.000270
Epoch 725 | Loss: 0.000275
Epoch 730 | Loss: 0.000270
Epoch 735 | Loss: 0.000269
Epoch 740 | Loss: 0.000271
Epoch 745 | Loss: 0.000267
Epoch 750 | Loss: 0.000275
Epoch 755 | Loss: 0.000274
Epoch 760 | Loss: 0.000271
Epoch 765 | Loss: 0.000270
Epoch 770 | Loss: 0.000275
Epoch 775 | Loss: 0.000272
Epoch 780 | Loss: 0.000268
Epoch 785 | Loss: 0.000271
Epoch 790 | Loss: 0.000266
Epoch 795 | Loss: 0.000271
  -- Saved model: lstm_model_epoch_800.pt
Epoch 800 | Loss: 0.000266
Epoch 805 | Loss: 0.000275
Epoch 810 | Loss: 0.000271
Epoch 815 | Loss: 0.000271
Epoch 820 | Loss: 0.000268
Epoch 825 | Loss: 0.000271
Epoch 830 | Loss: 0.000273
Epoch 835 | Loss: 0.000276
Epoch 840 | Loss: 0.000273
Epoch 845 | Loss: 0.000269
Epoch 850 | Loss: 0.000268
Epoch 855 | Loss: 0.000274
Epoch 860 | Loss: 0.000271
Epoch 865 | Loss: 0.000266
Epoch 870 | Loss: 0.000271
Epoch 875 | Loss: 0.000273
Epoch 880 | Loss: 0.000269
Epoch 885 | Loss: 0.000269
Epoch 890 | Loss: 0.000269
Epoch 895 | Loss: 0.000267
Epoch 899 | Loss: 0.000264
  -- Saved model: lstm_model_epoch_900.pt

Training Complete
Elapsed(s) = 1410
Evaluating RMSE for each prediction step
Calculated all predictions size: [3378, 10, 3]
Overall Metrics:
  RMSE (all): 0.015612 rad = 0.894 deg
  MAE  (all): 0.010565 rad = 0.605 deg

RMSE per angle (all samples, all steps):
  Roll  RMSE: 0.022073 rad = 1.265 deg
  Pitch RMSE: 0.013148 rad = 0.753 deg
  Yaw   RMSE: 0.008433 rad = 0.483 deg

RMSE per step
Step | Roll (deg) | Pitch (deg) | Yaw (deg)
-----+------------+-------------+-----------
   1 |   0.716608 |    0.428654 |  0.333163
   2 |   0.776368 |    0.428666 |  0.360379
   3 |   0.898354 |    0.484794 |  0.389940
   4 |   1.050081 |    0.569921 |  0.420953
   5 |   1.190181 |    0.654262 |  0.451533
   6 |   1.303631 |    0.726583 |  0.484150
   7 |   1.419237 |    0.804973 |  0.520524
   8 |   1.519261 |    0.897876 |  0.554018
   9 |   1.604662 |    1.010999 |  0.591377
  10 |   1.718963 |    1.146754 |  0.631320